{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21a41db3-efaf-4663-a10d-0219e281839a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f64fcda9-65e0-40b3-9c09-c1e231a20070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_patent = pd.read_csv('./patents_with_samsung_2024_04_23_2_lines.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e255132c-5e37-4ce9-9109-ed0fdb322f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Country</th>\n",
       "      <th>PatentNumber</th>\n",
       "      <th>ApplicationReference</th>\n",
       "      <th>Kind</th>\n",
       "      <th>Date</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>OrganizationName</th>\n",
       "      <th>SummaryOfInvention</th>\n",
       "      <th>Claims</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1132</td>\n",
       "      <td>US</td>\n",
       "      <td>11963590</td>\n",
       "      <td>utility</td>\n",
       "      <td>B2</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>A ring-type wearable device is disclosed. The ...</td>\n",
       "      <td>SAMSUNG ELECTRONICS CO., LTD.</td>\n",
       "      <td>{'h-0001 - CROSS-REFERENCE TO RELATED APPLICAT...</td>\n",
       "      <td>['1. A ring-type wearable device comprising: a...</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1188</td>\n",
       "      <td>US</td>\n",
       "      <td>11963647</td>\n",
       "      <td>utility</td>\n",
       "      <td>B2</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>A robot cleaner is provided. The robot cleaner...</td>\n",
       "      <td>SAMSUNG ELECTRONICS CO., LTD.</td>\n",
       "      <td>{'h-0001 - CROSS-REFERENCE TO RELATED APPLICAT...</td>\n",
       "      <td>['1. A robot cleaner comprising: a driver, inc...</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Country  PatentNumber ApplicationReference Kind        Date  \\\n",
       "0        1132      US      11963590              utility   B2  2024-04-23   \n",
       "1        1188      US      11963647              utility   B2  2024-04-23   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  A ring-type wearable device is disclosed. The ...   \n",
       "1  A robot cleaner is provided. The robot cleaner...   \n",
       "\n",
       "                OrganizationName  \\\n",
       "0  SAMSUNG ELECTRONICS CO., LTD.   \n",
       "1  SAMSUNG ELECTRONICS CO., LTD.   \n",
       "\n",
       "                                  SummaryOfInvention  \\\n",
       "0  {'h-0001 - CROSS-REFERENCE TO RELATED APPLICAT...   \n",
       "1  {'h-0001 - CROSS-REFERENCE TO RELATED APPLICAT...   \n",
       "\n",
       "                                              Claims  Year  \n",
       "0  ['1. A ring-type wearable device comprising: a...  2024  \n",
       "1  ['1. A robot cleaner comprising: a driver, inc...  2024  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data_patent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6a855e7-f61b-4458-b5b0-ff2b99677045",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/formatters.py:707\u001b[0m, in \u001b[0;36mPlainTextFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    700\u001b[0m stream \u001b[38;5;241m=\u001b[39m StringIO()\n\u001b[1;32m    701\u001b[0m printer \u001b[38;5;241m=\u001b[39m pretty\u001b[38;5;241m.\u001b[39mRepresentationPrinter(stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewline,\n\u001b[1;32m    703\u001b[0m     max_seq_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_seq_length,\n\u001b[1;32m    704\u001b[0m     singleton_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingleton_printers,\n\u001b[1;32m    705\u001b[0m     type_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_printers,\n\u001b[1;32m    706\u001b[0m     deferred_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeferred_printers)\n\u001b[0;32m--> 707\u001b[0m \u001b[43mprinter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    708\u001b[0m printer\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/lib/pretty.py:410\u001b[0m, in \u001b[0;36mRepresentationPrinter.pretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    407\u001b[0m                         \u001b[38;5;28;01mreturn\u001b[39;00m meth(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[1;32m    408\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mobject\u001b[39m \\\n\u001b[1;32m    409\u001b[0m                         \u001b[38;5;129;01mand\u001b[39;00m callable(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m--> 410\u001b[0m                     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_repr_pprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_pprint(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/lib/pretty.py:778\u001b[0m, in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;124;03m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[39;00m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;66;03m# Find newlines and replace them with p.break_()\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m lines \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgroup():\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py:338\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    336\u001b[0m                                  tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents)\n\u001b[1;32m    337\u001b[0m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[0;32m--> 338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor_str\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor_str.py:481\u001b[0m, in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_str\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 481\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_str_intern\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor_str.py:447\u001b[0m, in \u001b[0;36m_str_intern\u001b[0;34m(inp, tensor_contents)\u001b[0m\n\u001b[1;32m    445\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m _tensor_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dense(), indent)\n\u001b[1;32m    446\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 447\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m \u001b[43m_tensor_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstrided:\n\u001b[1;32m    450\u001b[0m     suffixes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayout=\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout))\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor_str.py:270\u001b[0m, in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, real_formatter, imag_formatter)\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 270\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m \u001b[43m_Formatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msummarize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor_str.py:103\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mlen\u001b[39m(value_str))\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 103\u001b[0m     nonzero_finite_vals \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmasked_select(tensor_view, \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misfinite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m&\u001b[39m tensor_view\u001b[38;5;241m.\u001b[39mne(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonzero_finite_vals\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;66;03m# no valid number, do nothing\u001b[39;00m\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.tensor([0.12,0.32]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f27e86a8-3dc3-4696-a436-ff00a36f419d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.2\n",
      "1.12.1+cu102\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1cf79a-4e5b-4b8b-a6a4-8e6065b594f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14575a9a-252f-4ad1-ada1-347900ffb786",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.40.2-py3-none-any.whl (9.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.0 MB 11.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.3.1)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3\n",
      "  Downloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
      "\u001b[K     |████████████████████████████████| 401 kB 69.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.23.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2024.5.10-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (777 kB)\n",
      "\u001b[K     |████████████████████████████████| 777 kB 47.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 35.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
      "Collecting tokenizers<0.20,>=0.19\n",
      "  Downloading tokenizers-0.19.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.6 MB 86.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "\u001b[K     |████████████████████████████████| 171 kB 85.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers) (1.25.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Installing collected packages: fsspec, huggingface-hub, regex, safetensors, tokenizers, transformers\n",
      "\u001b[33m  WARNING: The script huggingface-cli is installed in '/home/c7361293/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script transformers-cli is installed in '/home/c7361293/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed fsspec-2024.3.1 huggingface-hub-0.23.0 regex-2024.5.10 safetensors-0.4.3 tokenizers-0.19.1 transformers-4.40.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98788850-0460-42ec-a883-0ca613ef96c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version             \n",
      "---------------------------- --------------------\n",
      "absl-py                      1.3.0               \n",
      "ansible                      6.5.0               \n",
      "ansible-core                 2.13.5              \n",
      "anyio                        4.0.0               \n",
      "apturl                       0.5.2               \n",
      "argon2-cffi                  23.1.0              \n",
      "argon2-cffi-bindings         21.2.0              \n",
      "arviz                        0.13.0              \n",
      "asttokens                    2.0.8               \n",
      "astunparse                   1.6.3               \n",
      "async-lru                    2.0.4               \n",
      "atomicwrites                 1.1.5               \n",
      "attrs                        23.1.0              \n",
      "autobahn                     17.10.1             \n",
      "Automat                      0.8.0               \n",
      "Babel                        2.13.1              \n",
      "backcall                     0.2.0               \n",
      "bcrypt                       3.1.7               \n",
      "beautifulsoup4               4.8.2               \n",
      "bleach                       6.1.0               \n",
      "blinker                      1.4                 \n",
      "boto3                        1.25.1              \n",
      "botocore                     1.28.1              \n",
      "breezy                       3.0.2               \n",
      "Brlapi                       0.7.0               \n",
      "cachetools                   5.2.0               \n",
      "catkin-pkg                   1.0.0               \n",
      "catkin-pkg-modules           1.0.0               \n",
      "cbor                         1.0.0               \n",
      "certifi                      2019.11.28          \n",
      "cffi                         1.16.0              \n",
      "cftime                       1.6.2               \n",
      "chardet                      3.0.4               \n",
      "charset-normalizer           2.1.1               \n",
      "click                        8.0.4               \n",
      "cloud-init                   24.1.3              \n",
      "cloudpickle                  2.2.0               \n",
      "colorama                     0.4.3               \n",
      "comm                         0.1.4               \n",
      "command-not-found            0.3                 \n",
      "configobj                    5.0.6               \n",
      "constantly                   15.1.0              \n",
      "contourpy                    1.0.5               \n",
      "cryptography                 2.8                 \n",
      "cupshelpers                  1.0                 \n",
      "cvxopt                       1.2.3               \n",
      "cycler                       0.11.0              \n",
      "Cython                       0.29.14             \n",
      "dbus-python                  1.2.16              \n",
      "debugpy                      1.8.0               \n",
      "decorator                    5.1.1               \n",
      "defer                        1.0.6               \n",
      "defusedxml                   0.6.0               \n",
      "deprecat                     2.1.1               \n",
      "Deprecated                   1.2.7               \n",
      "dgl                          0.9.1               \n",
      "dill                         0.3.6               \n",
      "distro                       1.4.0               \n",
      "distro-info                  0.23+ubuntu1.1      \n",
      "docutils                     0.16                \n",
      "dulwich                      0.19.15             \n",
      "empy                         3.3.2               \n",
      "entrypoints                  0.3                 \n",
      "et-xmlfile                   1.0.1               \n",
      "exceptiongroup               1.1.3               \n",
      "executing                    1.1.1               \n",
      "fastimport                   0.9.8               \n",
      "fastjsonschema               2.18.1              \n",
      "fastprogress                 1.0.3               \n",
      "filelock                     3.8.0               \n",
      "fire                         0.4.0               \n",
      "flatbuffers                  22.10.26            \n",
      "fonttools                    4.38.0              \n",
      "fsspec                       2024.3.1            \n",
      "gast                         0.4.0               \n",
      "gensim                       4.2.0               \n",
      "google-auth                  2.13.0              \n",
      "google-auth-oauthlib         0.4.6               \n",
      "google-pasta                 0.2.0               \n",
      "gpg                          1.13.1              \n",
      "grpcio                       1.50.0              \n",
      "h5py                         3.7.0               \n",
      "html5lib                     1.0.1               \n",
      "httplib2                     0.14.0              \n",
      "huggingface-hub              0.23.0              \n",
      "hyperlink                    19.0.0              \n",
      "idna                         2.8                 \n",
      "imageio                      2.22.2              \n",
      "importlib-metadata           5.0.0               \n",
      "importlib-resources          6.1.0               \n",
      "incremental                  16.10.1             \n",
      "ipykernel                    6.26.0              \n",
      "ipython                      8.5.0               \n",
      "ipython-genutils             0.2.0               \n",
      "jdcal                        1.0                 \n",
      "jedi                         0.18.1              \n",
      "Jinja2                       3.1.2               \n",
      "jmespath                     1.0.1               \n",
      "joblib                       1.2.0               \n",
      "json5                        0.9.14              \n",
      "jsonpatch                    1.22                \n",
      "jsonpointer                  2.0                 \n",
      "jsonschema                   4.19.1              \n",
      "jsonschema-specifications    2023.7.1            \n",
      "jupyter-client               8.5.0               \n",
      "jupyter-core                 5.4.0               \n",
      "jupyter-events               0.8.0               \n",
      "jupyter-lsp                  2.2.0               \n",
      "jupyter-server               2.9.1               \n",
      "jupyter-server-terminals     0.4.4               \n",
      "jupyterlab                   4.0.7               \n",
      "jupyterlab-pygments          0.2.2               \n",
      "jupyterlab-server            2.25.0              \n",
      "keras                        2.10.0              \n",
      "Keras-Preprocessing          1.1.2               \n",
      "keyring                      18.0.1              \n",
      "kiwisolver                   1.4.4               \n",
      "language-selector            0.1                 \n",
      "laspy                        2.3.0               \n",
      "launchpadlib                 1.10.13             \n",
      "lazr.restfulclient           0.14.2              \n",
      "lazr.uri                     1.0.3               \n",
      "libclang                     14.0.6              \n",
      "llvmlite                     0.39.1              \n",
      "louis                        3.12.0              \n",
      "lxml                         4.9.1               \n",
      "lz4                          3.0.2+dfsg          \n",
      "macaroonbakery               1.3.1               \n",
      "Mako                         1.1.0               \n",
      "Markdown                     3.4.1               \n",
      "MarkupSafe                   2.1.1               \n",
      "matplotlib                   3.6.1               \n",
      "matplotlib-inline            0.1.6               \n",
      "mistune                      3.0.2               \n",
      "mlxtend                      0.21.0              \n",
      "more-itertools               4.2.0               \n",
      "mpi4py                       3.0.3               \n",
      "mpmath                       1.2.1               \n",
      "nbclient                     0.8.0               \n",
      "nbconvert                    7.9.2               \n",
      "nbformat                     5.9.2               \n",
      "nest-asyncio                 1.5.8               \n",
      "netCDF4                      1.6.1               \n",
      "netifaces                    0.10.4              \n",
      "networkx                     2.8.7               \n",
      "nltk                         3.4.5               \n",
      "nose                         1.3.7               \n",
      "notebook                     7.0.6               \n",
      "notebook-shim                0.2.3               \n",
      "numba                        0.56.3              \n",
      "numexpr                      2.8.4               \n",
      "numpy                        1.23.4              \n",
      "oauthlib                     3.1.0               \n",
      "olefile                      0.46                \n",
      "opencv-python                4.6.0.66            \n",
      "openpyxl                     3.0.3               \n",
      "opt-einsum                   3.3.0               \n",
      "overrides                    7.4.0               \n",
      "packaging                    21.3                \n",
      "pandas                       1.5.1               \n",
      "pandocfilters                1.5.0               \n",
      "parameterized                0.7.0               \n",
      "paramiko                     2.6.0               \n",
      "parso                        0.8.3               \n",
      "patsy                        0.5.1               \n",
      "pexpect                      4.6.0               \n",
      "pickleshare                  0.7.5               \n",
      "Pillow                       9.2.0               \n",
      "pip                          20.0.2              \n",
      "pkgutil-resolve-name         1.3.10              \n",
      "platformdirs                 3.11.0              \n",
      "plotly                       4.4.1               \n",
      "pluggy                       0.13.0              \n",
      "prometheus-client            0.17.1              \n",
      "prompt-toolkit               3.0.31              \n",
      "protobuf                     3.19.6              \n",
      "psutil                       5.9.3               \n",
      "ptyprocess                   0.7.0               \n",
      "pure-eval                    0.2.2               \n",
      "py                           1.8.1               \n",
      "py-ubjson                    0.14.0              \n",
      "py4j                         0.10.9.5            \n",
      "pyasn1                       0.4.2               \n",
      "pyasn1-modules               0.2.1               \n",
      "pybboxes                     0.1.5               \n",
      "pycairo                      1.16.2              \n",
      "pycparser                    2.21                \n",
      "pycrypto                     2.6.1               \n",
      "pycryptodomex                3.6.1               \n",
      "pycups                       1.9.73              \n",
      "pydot                        1.4.1               \n",
      "PyGithub                     1.43.7              \n",
      "Pygments                     2.13.0              \n",
      "PyGObject                    3.36.0              \n",
      "pygpu                        0.7.6               \n",
      "PyHamcrest                   1.9.0               \n",
      "PyJWT                        1.7.1               \n",
      "pymacaroons                  0.13.0              \n",
      "pymc3                        3.11.5              \n",
      "PyNaCl                       1.3.0               \n",
      "pyntcloud                    0.3.1               \n",
      "PyOpenGL                     3.1.0               \n",
      "pyOpenSSL                    19.0.0              \n",
      "pyparsing                    3.0.9               \n",
      "pypng                        0.0.20              \n",
      "PyQRCode                     1.2.1               \n",
      "PyQt5                        5.14.1              \n",
      "pyqtgraph                    0.11.0rc0           \n",
      "pyRFC3339                    1.1                 \n",
      "pyrsistent                   0.15.5              \n",
      "pyserial                     3.4                 \n",
      "pyspark                      3.3.1               \n",
      "pytest                       4.6.9               \n",
      "python-apt                   2.0.1+ubuntu0.20.4.1\n",
      "python-dateutil              2.8.2               \n",
      "python-debian                0.1.36+ubuntu1.1    \n",
      "python-gitlab                2.0.1               \n",
      "python-gnupg                 0.4.5               \n",
      "python-json-logger           2.0.7               \n",
      "python-snappy                0.5.3               \n",
      "PyTrie                       0.2                 \n",
      "pytz                         2022.5              \n",
      "PyWavelets                   1.4.1               \n",
      "pyxdg                        0.26                \n",
      "PyYAML                       5.3.1               \n",
      "pyzmq                        25.1.1              \n",
      "referencing                  0.30.2              \n",
      "regex                        2024.5.10           \n",
      "reportlab                    3.5.34              \n",
      "requests                     2.28.1              \n",
      "requests-oauthlib            1.3.1               \n",
      "requests-unixsocket          0.2.0               \n",
      "resolvelib                   0.8.1               \n",
      "retrying                     1.3.3               \n",
      "rfc3339-validator            0.1.4               \n",
      "rfc3986-validator            0.1.1               \n",
      "roman                        2.0.0               \n",
      "rosdep                       0.24.0              \n",
      "rosdep-modules               0.24.0              \n",
      "rosdistro                    0.9.1               \n",
      "rosdistro-modules            0.9.1               \n",
      "rosinstall                   0.7.8               \n",
      "rosinstall-generator         0.1.23              \n",
      "rospkg                       1.5.1               \n",
      "rospkg-modules               1.5.1               \n",
      "rpds-py                      0.10.6              \n",
      "rsa                          4.9                 \n",
      "s3transfer                   0.6.0               \n",
      "safetensors                  0.4.3               \n",
      "sahi                         0.10.8              \n",
      "scikit-image                 0.19.3              \n",
      "scikit-learn                 1.1.3               \n",
      "scipy                        1.9.3               \n",
      "screen-resolution-extra      0.0.0               \n",
      "seaborn                      0.12.1              \n",
      "SecretStorage                2.3.1               \n",
      "semver                       2.13.0              \n",
      "Send2Trash                   1.8.2               \n",
      "sentencepiece                0.2.0               \n",
      "service-identity             18.1.0              \n",
      "setuptools                   45.2.0              \n",
      "shap                         0.41.0              \n",
      "Shapely                      1.8.5.post1         \n",
      "simplejson                   3.16.0              \n",
      "sip                          4.19.21             \n",
      "six                          1.14.0              \n",
      "sklearn-som                  1.1.0               \n",
      "slicer                       0.0.7               \n",
      "smart-open                   6.2.0               \n",
      "sniffio                      1.3.0               \n",
      "sos                          4.5.6               \n",
      "soupsieve                    1.9.5               \n",
      "spektral                     1.2.0               \n",
      "ssh-import-id                5.10                \n",
      "stack-data                   0.5.1               \n",
      "statsmodels                  0.11.1              \n",
      "sympy                        1.11.1              \n",
      "systemd-python               234                 \n",
      "tensorboard                  2.10.1              \n",
      "tensorboard-data-server      0.6.1               \n",
      "tensorboard-plugin-wit       1.8.1               \n",
      "tensorflow                   2.10.0              \n",
      "tensorflow-estimator         2.10.0              \n",
      "tensorflow-io-gcs-filesystem 0.27.0              \n",
      "tensorrt                     10.0.1              \n",
      "tensorrt-dispatch            10.0.1              \n",
      "tensorrt-lean                10.0.1              \n",
      "termcolor                    2.0.1               \n",
      "terminado                    0.17.1              \n",
      "terminaltables               3.1.10              \n",
      "tesserocr                    2.5.0               \n",
      "Theano                       1.0.4               \n",
      "Theano-PyMC                  1.1.2               \n",
      "thop                         0.1.1.post2209072238\n",
      "threadpoolctl                3.1.0               \n",
      "tifffile                     2022.10.10          \n",
      "tinycss2                     1.2.1               \n",
      "tokenizers                   0.19.1              \n",
      "tomli                        2.0.1               \n",
      "torch                        1.12.1              \n",
      "torchvision                  0.13.1              \n",
      "tornado                      6.3.3               \n",
      "tqdm                         4.64.1              \n",
      "traitlets                    5.5.0               \n",
      "transformers                 4.40.2              \n",
      "Twisted                      18.9.0              \n",
      "txaio                        2.10.0              \n",
      "typing-extensions            4.4.0               \n",
      "u-msgpack-python             2.1                 \n",
      "ubuntu-drivers-common        0.0.0               \n",
      "ubuntu-pro-client            8001                \n",
      "ufw                          0.36                \n",
      "unattended-upgrades          0.1                 \n",
      "urllib3                      1.25.8              \n",
      "vcstools                     0.1.42              \n",
      "wadllib                      1.3.3               \n",
      "wcwidth                      0.2.5               \n",
      "webencodings                 0.5.1               \n",
      "websocket-client             1.6.4               \n",
      "Werkzeug                     2.2.2               \n",
      "wheel                        0.34.2              \n",
      "word2vec                     0.11.1              \n",
      "wrapt                        1.14.1              \n",
      "wsaccel                      0.6.2               \n",
      "wstool                       0.1.18              \n",
      "xarray                       2022.10.0           \n",
      "xarray-einstats              0.3.0               \n",
      "xkit                         0.0.0               \n",
      "xlrd                         1.1.0               \n",
      "xlwt                         1.3.0               \n",
      "yellowbrick                  1.5                 \n",
      "yolov5                       6.2.3               \n",
      "zipp                         1.0.0               \n",
      "zope.interface               4.7.1               \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f200c743-926b-46e7-9874-b619f07ccaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 13.4 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5bd7f87-03be-42af-b10a-746cb1e4b921",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:08<00:00,  2.93s/it]\n",
      "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:146: UserWarning: \n",
      "NVIDIA A40 with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the NVIDIA A40 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (1): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (2): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (3): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (4): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (5): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (6): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (7): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (8): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (9): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (10): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (11): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (12): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (13): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (14): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (15): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (16): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (17): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (18): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (19): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (20): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (21): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (22): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (23): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (24): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (25): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (26): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (27): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (28): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (29): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (30): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (31): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "\n",
    "# Initialize the tokenizer and model\n",
    "model_name_or_path = \"/home/c7361293/triz_llm/llama-2-7b-chat/model\"\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_name_or_path)\n",
    "model = LlamaForCausalLM.from_pretrained(model_name_or_path)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bffa900c-42f9-48d1-b30c-74574b4b70c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_patent = pd.read_csv('./patents_with_samsung_2024_04_23_2_lines.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5515ebc-749b-40cc-8bf7-42464c15ebeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Country</th>\n",
       "      <th>PatentNumber</th>\n",
       "      <th>ApplicationReference</th>\n",
       "      <th>Kind</th>\n",
       "      <th>Date</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>OrganizationName</th>\n",
       "      <th>SummaryOfInvention</th>\n",
       "      <th>Claims</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1132</td>\n",
       "      <td>US</td>\n",
       "      <td>11963590</td>\n",
       "      <td>utility</td>\n",
       "      <td>B2</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>A ring-type wearable device is disclosed. The ...</td>\n",
       "      <td>SAMSUNG ELECTRONICS CO., LTD.</td>\n",
       "      <td>{'h-0001 - CROSS-REFERENCE TO RELATED APPLICAT...</td>\n",
       "      <td>['1. A ring-type wearable device comprising: a...</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1188</td>\n",
       "      <td>US</td>\n",
       "      <td>11963647</td>\n",
       "      <td>utility</td>\n",
       "      <td>B2</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>A robot cleaner is provided. The robot cleaner...</td>\n",
       "      <td>SAMSUNG ELECTRONICS CO., LTD.</td>\n",
       "      <td>{'h-0001 - CROSS-REFERENCE TO RELATED APPLICAT...</td>\n",
       "      <td>['1. A robot cleaner comprising: a driver, inc...</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Country  PatentNumber ApplicationReference Kind        Date  \\\n",
       "0        1132      US      11963590              utility   B2  2024-04-23   \n",
       "1        1188      US      11963647              utility   B2  2024-04-23   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  A ring-type wearable device is disclosed. The ...   \n",
       "1  A robot cleaner is provided. The robot cleaner...   \n",
       "\n",
       "                OrganizationName  \\\n",
       "0  SAMSUNG ELECTRONICS CO., LTD.   \n",
       "1  SAMSUNG ELECTRONICS CO., LTD.   \n",
       "\n",
       "                                  SummaryOfInvention  \\\n",
       "0  {'h-0001 - CROSS-REFERENCE TO RELATED APPLICAT...   \n",
       "1  {'h-0001 - CROSS-REFERENCE TO RELATED APPLICAT...   \n",
       "\n",
       "                                              Claims  Year  \n",
       "0  ['1. A ring-type wearable device comprising: a...  2024  \n",
       "1  ['1. A robot cleaner comprising: a driver, inc...  2024  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data_patent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6eb1ec51-bdad-4f78-80d5-5cffa5da25c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:09<00:00,  3.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 59\u001b[0m\n\u001b[1;32m     57\u001b[0m summaries \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m abstract \u001b[38;5;129;01min\u001b[39;00m data_patent[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAbstract\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m---> 59\u001b[0m     summary \u001b[38;5;241m=\u001b[39m \u001b[43msummarize_abstract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mabstract\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     summaries\u001b[38;5;241m.\u001b[39mappend(summary)\n\u001b[1;32m     62\u001b[0m data_patent[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSummaryofPatent\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m summaries\n",
      "Cell \u001b[0;32mIn [19], line 38\u001b[0m, in \u001b[0;36msummarize_abstract\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#  # Ensure that the attention mask and the pad token are set correctly\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# if 'attention_mask' not in inputs:\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m#     inputs['attention_mask'] = torch.ones_like(inputs['input_ids'])\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# if 'pad_token_id' not in tokenizer.vocab:\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#     tokenizer.pad_token = tokenizer.eos_token\u001b[39;00m\n\u001b[1;32m     36\u001b[0m inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 38\u001b[0m output_sequences \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Ensures more deterministic outputs\u001b[39;49;00m\n\u001b[1;32m     44\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# print(tokenizer.decode(output_sequences, skip_special_tokens=True))\u001b[39;00m\n\u001b[1;32m     47\u001b[0m text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(output_sequences[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/generation/utils.py:1442\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1435\u001b[0m \u001b[38;5;66;03m# decoder-only models should use left-padding for generation\u001b[39;00m\n\u001b[1;32m   1436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder:\n\u001b[1;32m   1437\u001b[0m     \u001b[38;5;66;03m# If `input_ids` was given, check if the last id in any sequence is `pad_token_id`\u001b[39;00m\n\u001b[1;32m   1438\u001b[0m     \u001b[38;5;66;03m# Note: If using, `inputs_embeds` this check does not work, because we want to be more hands-off.\u001b[39;00m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1440\u001b[0m         generation_config\u001b[38;5;241m.\u001b[39mpad_token_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1441\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs_tensor\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m-> 1442\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39msum(\u001b[43minputs_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1443\u001b[0m     ):\n\u001b[1;32m   1444\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m   1445\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA decoder-only architecture is being used, but right-padding was detected! For correct \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1446\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration results, please set `padding_side=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` when initializing the tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1447\u001b[0m         )\n\u001b[1;32m   1449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[1;32m   1450\u001b[0m     \u001b[38;5;66;03m# if model is encoder decoder encoder_outputs are created\u001b[39;00m\n\u001b[1;32m   1451\u001b[0m     \u001b[38;5;66;03m# and added to `model_kwargs`\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "\n",
    "\n",
    "# Initialize the tokenizer and model\n",
    "model_name_or_path = \"/home/c7361293/triz_llm/llama-2-7b-chat/model\"\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_name_or_path)\n",
    "model = LlamaForCausalLM.from_pretrained(model_name_or_path)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "model.to(device)\n",
    "\n",
    "# Function to summarize text\n",
    "def summarize_abstract(text):\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    # prompt = f\"Summarize this: {text} in 20 words\"\n",
    "    prompt = f\"{text} \\n Summarize the provided text focusing on the key improvement aimed at by the research, any potential drawbacks or degrading parameters mentioned, and any information on energy efficiency. The summary should clearly outline the main objectives, highlight any challenges or limitations if discussed, and note the presence or absence of energy efficiency details. Please keep the summary concise and output only the summary, ideally within five lines and start with 'Summary:'\"\n",
    "    # Check and set the padding token\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token  # Typically the EOS token can be used as pad token\n",
    "\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    #  # Ensure that the attention mask and the pad token are set correctly\n",
    "    # if 'attention_mask' not in inputs:\n",
    "    #     inputs['attention_mask'] = torch.ones_like(inputs['input_ids'])\n",
    "    # if 'pad_token_id' not in tokenizer.vocab:\n",
    "    #     tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    inputs = inputs.to(device)\n",
    "    \n",
    "    output_sequences = model.generate(\n",
    "        input_ids=inputs['input_ids'], \n",
    "        attention_mask=inputs['attention_mask'],\n",
    "        max_length=5000, \n",
    "        num_return_sequences=1,\n",
    "        do_sample=False  # Ensures more deterministic outputs\n",
    "    )\n",
    "\n",
    "    # print(tokenizer.decode(output_sequences, skip_special_tokens=True))\n",
    "    text = tokenizer.decode(output_sequences[0], skip_special_tokens=True)\n",
    "    summary_index = text.find(\"Summary:\\n\")\n",
    "    summary = text\n",
    "    if summary_index != -1:\n",
    "        # Extract the text from \"Begin Summary:\" to the end of the string\n",
    "         summary = text[summary_index:]\n",
    "\n",
    "    return summary\n",
    "\n",
    "# Apply summarization to each abstract and store results in a new column\n",
    "summaries = []\n",
    "for abstract in data_patent['Abstract']:\n",
    "    summary = summarize_abstract(abstract)\n",
    "    summaries.append(summary)\n",
    "\n",
    "data_patent['SummaryofPatent'] = summaries\n",
    "data_patent.to_csv('./summarized_patents/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "889bd467-3f32-4479-9d3d-93da7960a101",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nvidia' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnvidia\u001b[49m\u001b[38;5;241m-\u001b[39msmi\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nvidia' is not defined"
     ]
    }
   ],
   "source": [
    "nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90f7c37a-d1b0-49f3-9028-fc59183d2383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# del model\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "389e4682-000e-4f29-afdc-a37a67c50ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |   25769 MB |   25769 MB |   25769 MB |     512 B  |\n",
      "|       from large pool |   25704 MB |   25704 MB |   25704 MB |       0 B  |\n",
      "|       from small pool |      65 MB |      65 MB |      65 MB |     512 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |   25769 MB |   25769 MB |   25769 MB |     512 B  |\n",
      "|       from large pool |   25704 MB |   25704 MB |   25704 MB |       0 B  |\n",
      "|       from small pool |      65 MB |      65 MB |      65 MB |     512 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |   25770 MB |   25770 MB |   25770 MB |       0 B  |\n",
      "|       from large pool |   25704 MB |   25704 MB |   25704 MB |       0 B  |\n",
      "|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |     988 KB |    2047 KB |   34816 KB |   33828 KB |\n",
      "|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |\n",
      "|       from small pool |     988 KB |    2047 KB |   34816 KB |   33828 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     389    |     390    |     390    |       1    |\n",
      "|       from large pool |     226    |     226    |     226    |       0    |\n",
      "|       from small pool |     163    |     164    |     164    |       1    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     389    |     390    |     390    |       1    |\n",
      "|       from large pool |     226    |     226    |     226    |       0    |\n",
      "|       from small pool |     163    |     164    |     164    |       1    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     259    |     259    |     259    |       0    |\n",
      "|       from large pool |     226    |     226    |     226    |       0    |\n",
      "|       from small pool |      33    |      33    |      33    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       1    |       2    |      33    |      32    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       1    |       2    |      33    |      32    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.synchronize()\n",
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87a899e5-dee7-49c9-a0c2-252e6bdaac53",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming `model` is your PyTorch model\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mparameters())\u001b[38;5;241m.\u001b[39mis_cuda:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel is on CUDA\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "# Assuming `model` is your PyTorch model\n",
    "if next(model.parameters()).is_cuda:\n",
    "    print(\"Model is on CUDA\")\n",
    "else:\n",
    "    print(\"Model is not on CUDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de294347-395f-4a42-bd6d-2f3523fe5d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
